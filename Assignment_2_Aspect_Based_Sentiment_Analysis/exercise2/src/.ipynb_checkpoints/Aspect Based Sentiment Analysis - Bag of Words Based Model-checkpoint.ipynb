{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = '/home/ayush/Graduate_Study/Natural_Language_Processing_Course/Assignment_2/exercise2/data/traindata.csv'\n",
    "dev_dataset = '/home/ayush/Graduate_Study/Natural_Language_Processing_Course/Assignment_2/exercise2/data/devdata.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = ['Polarity','Aspect_Category','Specific_Target_Aspect_Term','Character_Offset','Sentence']\n",
    "train_df = pd.read_csv(train_dataset,sep='\\t',names=col_names)\n",
    "dev_df = pd.read_csv(dev_dataset,sep='\\t',names=col_names)\n",
    "\n",
    "spacy_parser = spacy.load('en')\n",
    "vocab_size = 8000\n",
    "num_aspect_categories = 12 # There are 12 Aspect Categories\n",
    "num_sentiments = 3 # Positive, Negative and Neutral\n",
    "\n",
    "#Drop the character Offset Dataframe\n",
    "train_df = train_df.drop(columns=['Character_Offset'])\n",
    "dev_df = dev_df.drop(columns=['Character_Offset'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Shape:  (1503, 4)\n",
      "Dev Data Shape:  (376, 4)\n"
     ]
    }
   ],
   "source": [
    "print('Train Data Shape: ',train_df.shape)\n",
    "print('Dev Data Shape: ',dev_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Polarity           Aspect_Category Specific_Target_Aspect_Term  \\\n",
      "0   positive          AMBIENCE#GENERAL                     seating   \n",
      "1   positive          AMBIENCE#GENERAL                   trattoria   \n",
      "2   positive              FOOD#QUALITY                        food   \n",
      "3   negative           SERVICE#GENERAL                       STAFF   \n",
      "4   positive        FOOD#STYLE_OPTIONS                        menu   \n",
      "5   positive              FOOD#QUALITY                        tuna   \n",
      "6   negative           SERVICE#GENERAL                       staff   \n",
      "7   negative           SERVICE#GENERAL                     service   \n",
      "8   positive        FOOD#STYLE_OPTIONS                    BBQ ribs   \n",
      "9   positive          AMBIENCE#GENERAL                       place   \n",
      "10  negative              FOOD#QUALITY         appetizer of olives   \n",
      "11  negative              FOOD#QUALITY                       foods   \n",
      "12  positive            DRINKS#QUALITY                      drinks   \n",
      "13  positive              FOOD#QUALITY                       rolls   \n",
      "14  positive              FOOD#QUALITY              Prix Fixe menu   \n",
      "15  positive              FOOD#QUALITY                    scallops   \n",
      "16  positive          AMBIENCE#GENERAL                    Ambience   \n",
      "17  positive          AMBIENCE#GENERAL       late night atmosphere   \n",
      "18  positive              FOOD#QUALITY                  pear torte   \n",
      "19  positive              FOOD#QUALITY        spicy Italian cheese   \n",
      "20  positive              FOOD#QUALITY                       filet   \n",
      "21  negative              FOOD#QUALITY                  quesadilla   \n",
      "22  negative  RESTAURANT#MISCELLANEOUS                       place   \n",
      "23  positive              FOOD#QUALITY                        food   \n",
      "24  positive           SERVICE#GENERAL                     Service   \n",
      "25  positive              FOOD#QUALITY                      bagels   \n",
      "26  negative        RESTAURANT#GENERAL                  restaurant   \n",
      "27  positive              FOOD#QUALITY                french fries   \n",
      "28  positive              FOOD#QUALITY                 rice dishes   \n",
      "29  positive          AMBIENCE#GENERAL                    ambience   \n",
      "\n",
      "                                             Sentence  \n",
      "0   short and sweet â€“ seating is great:it's romant...  \n",
      "1   This quaint and romantic trattoria is at the t...  \n",
      "2   The have over 100 different beers to offer thi...  \n",
      "3                         THIS STAFF SHOULD BE FIRED.  \n",
      "4   The menu looked great, and the waiter was very...  \n",
      "5         The tuna and wasabe potatoes are excellent.  \n",
      "6   The whole set up is truly unprofessional and I...  \n",
      "7   sometimes i get bad food and bad service, some...  \n",
      "8   This place has the best Chinese style BBQ ribs...  \n",
      "9          Great place to relax and enjoy your dinner  \n",
      "10  The bread we received was horrible - rock hard...  \n",
      "11  We thought that this place is using too much o...  \n",
      "12     Always good drinks and service is pretty good;  \n",
      "13  We are very particular about sushi and were bo...  \n",
      "14  The Prix Fixe menu is worth every penny and yo...  \n",
      "15  We had the scallops as an appetizer and they w...  \n",
      "16  Ambience is so cute and quaint, good for busin...  \n",
      "17  But the best part about LS is the late night a...  \n",
      "18  The dessert (we had a pear torte) was good - b...  \n",
      "19  The pesto pizza was excellent, thin-crust pizz...  \n",
      "20  I had fish and my husband had the filet - both...  \n",
      "21  My quesadilla tasted like it had been made by ...  \n",
      "22                     This place is incredibly tiny.  \n",
      "23  I found the food to be outstanding, particular...  \n",
      "24                  Service was prompt and courteous.  \n",
      "25  delicious bagels, especially when right out of...  \n",
      "26  I have never left a restaurant feeling as if i...  \n",
      "27  My husband said he could've eaten several more...  \n",
      "28  I also recommend the rice dishes or the differ...  \n",
      "29  I highly recommend Cafe St. Bart's for their f...  \n"
     ]
    }
   ],
   "source": [
    "print(train_df.head(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Polarity           Aspect_Category      Specific_Target_Aspect_Term  \\\n",
      "0   positive          LOCATION#GENERAL                     neighborhood   \n",
      "1   negative        RESTAURANT#GENERAL                            place   \n",
      "2   positive              FOOD#QUALITY                             Fish   \n",
      "3   negative           SERVICE#GENERAL                          manager   \n",
      "4    neutral            DRINKS#QUALITY                       margaritas   \n",
      "5   negative          AMBIENCE#GENERAL                            decor   \n",
      "6   negative        RESTAURANT#GENERAL                   Haru on Park S   \n",
      "7   positive           SERVICE#GENERAL                            staff   \n",
      "8   positive           SERVICE#GENERAL                          hostess   \n",
      "9   negative  RESTAURANT#MISCELLANEOUS                              BFC   \n",
      "10  positive           SERVICE#GENERAL                          service   \n",
      "11  negative        FOOD#STYLE_OPTIONS  salt encrusted shrimp appetizer   \n",
      "12  positive            DRINKS#QUALITY                         Gigondas   \n",
      "13  positive               FOOD#PRICES                            sushi   \n",
      "14  positive              FOOD#QUALITY                  fried dumplings   \n",
      "15  positive      DRINKS#STYLE_OPTIONS                        wine list   \n",
      "16  positive              FOOD#QUALITY                             food   \n",
      "17  positive        RESTAURANT#GENERAL                              bar   \n",
      "18  positive              FOOD#QUALITY                             food   \n",
      "19  positive              FOOD#QUALITY                     thai cuisine   \n",
      "20  positive           SERVICE#GENERAL                          Service   \n",
      "21  positive              FOOD#QUALITY                          seafood   \n",
      "22  positive        FOOD#STYLE_OPTIONS                             menu   \n",
      "23  positive      DRINKS#STYLE_OPTIONS                        wine list   \n",
      "24  positive              FOOD#QUALITY                            Pizza   \n",
      "25  negative              FOOD#QUALITY                             food   \n",
      "26  negative         RESTAURANT#PRICES                       restaurant   \n",
      "27  positive              FOOD#QUALITY                             food   \n",
      "28  positive          LOCATION#GENERAL                            block   \n",
      "29  positive        RESTAURANT#GENERAL                  Planet Thailand   \n",
      "\n",
      "                                             Sentence  \n",
      "0   great food, great wine list, great service in ...  \n",
      "1         I thought this place was totally overrated.  \n",
      "2                              Fish is so very fresh.  \n",
      "3   I showed it to the manager, and he smilingly a...  \n",
      "4   The food we ordered was excellent, although I ...  \n",
      "5   This place has totally weird decor, stairs goi...  \n",
      "6                Haru on Park S is simply disgusting.  \n",
      "7   The staff there is very attentive and down to ...  \n",
      "8                      The hostess was very pleasant.  \n",
      "9   As BFC doesn't take reservations you almost al...  \n",
      "10                                Good, fast service.  \n",
      "11  I believe there were 2 shrimp in the \"salt enc...  \n",
      "12  Great wine selection, Gigondas is worth the pr...  \n",
      "13       This is some really good, inexpensive sushi.  \n",
      "14                     The fried dumplings are GREAT!  \n",
      "15                        The wine list is excellent.  \n",
      "16  Everyone raved about the atmosphere (elegant r...  \n",
      "17  After really enjoying ourselves at the bar we ...  \n",
      "18  The food we ordered was excellent, although I ...  \n",
      "19  I would definitely recommend SEA if you like t...  \n",
      "20       Service was very prompt but slightly rushed.  \n",
      "21  The seafood is amazing, there's a good wine li...  \n",
      "22  With the great variety on the menu , I eat her...  \n",
      "23  The wine list was extensive - though the staff...  \n",
      "24                   Pizza here is consistently good.  \n",
      "25  So what you really end up paying for is the re...  \n",
      "26  I have never left a restaurant feeling as if i...  \n",
      "27  The food was pretty tradional but it was hot a...  \n",
      "28         Located at the end of a magnificent block.  \n",
      "29  Planet Thailand has always been a hit with me ...  \n"
     ]
    }
   ],
   "source": [
    "print(dev_df.head(30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Build the Aspect  Categories Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "aspect_categories_model = Sequential()\n",
    "aspect_categories_model.add(Dense(512, input_shape=(vocab_size,), activation='relu'))\n",
    "aspect_categories_model.add(Dense(num_aspect_categories, activation='softmax'))\n",
    "aspect_categories_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Bag of Words Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(num_words=vocab_size)\n",
    "tokenizer.fit_on_texts(train_df.Sentence)\n",
    "aspect_tokenized = pd.DataFrame(tokenizer.texts_to_matrix(train_df.Specific_Target_Aspect_Term))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding the Aspect Category to Binary Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "aspect_integer_category = label_encoder.fit_transform(train_df.Aspect_Category)\n",
    "aspect_dummy_category = to_categorical(aspect_integer_category)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Aspect Categories Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "1503/1503 [==============================] - 1s 691us/step - loss: 2.1140 - acc: 0.4950\n",
      "Epoch 2/40\n",
      "1503/1503 [==============================] - 0s 186us/step - loss: 1.3288 - acc: 0.5975\n",
      "Epoch 3/40\n",
      "1503/1503 [==============================] - 0s 184us/step - loss: 0.9263 - acc: 0.7392\n",
      "Epoch 4/40\n",
      "1503/1503 [==============================] - 0s 184us/step - loss: 0.7100 - acc: 0.7951\n",
      "Epoch 5/40\n",
      "1503/1503 [==============================] - 0s 202us/step - loss: 0.5856 - acc: 0.8303\n",
      "Epoch 6/40\n",
      "1503/1503 [==============================] - 0s 200us/step - loss: 0.5114 - acc: 0.8397 0s - loss: 0.5199 - acc: 0.8\n",
      "Epoch 7/40\n",
      "1503/1503 [==============================] - 0s 190us/step - loss: 0.4687 - acc: 0.8463\n",
      "Epoch 8/40\n",
      "1503/1503 [==============================] - 0s 189us/step - loss: 0.4396 - acc: 0.8443\n",
      "Epoch 9/40\n",
      "1503/1503 [==============================] - 0s 189us/step - loss: 0.4194 - acc: 0.8443\n",
      "Epoch 10/40\n",
      "1503/1503 [==============================] - 0s 188us/step - loss: 0.4067 - acc: 0.8423\n",
      "Epoch 11/40\n",
      "1503/1503 [==============================] - 0s 186us/step - loss: 0.3993 - acc: 0.8436\n",
      "Epoch 12/40\n",
      "1503/1503 [==============================] - 0s 186us/step - loss: 0.3891 - acc: 0.8483\n",
      "Epoch 13/40\n",
      "1503/1503 [==============================] - 0s 186us/step - loss: 0.3845 - acc: 0.8436\n",
      "Epoch 14/40\n",
      "1503/1503 [==============================] - 0s 185us/step - loss: 0.3811 - acc: 0.8450\n",
      "Epoch 15/40\n",
      "1503/1503 [==============================] - 0s 189us/step - loss: 0.3817 - acc: 0.8337\n",
      "Epoch 16/40\n",
      "1503/1503 [==============================] - 0s 193us/step - loss: 0.3765 - acc: 0.8430\n",
      "Epoch 17/40\n",
      "1503/1503 [==============================] - 0s 188us/step - loss: 0.3742 - acc: 0.8443\n",
      "Epoch 18/40\n",
      "1503/1503 [==============================] - 0s 188us/step - loss: 0.3703 - acc: 0.8436\n",
      "Epoch 19/40\n",
      "1503/1503 [==============================] - 0s 184us/step - loss: 0.3700 - acc: 0.8377\n",
      "Epoch 20/40\n",
      "1503/1503 [==============================] - 0s 185us/step - loss: 0.3698 - acc: 0.8423\n",
      "Epoch 21/40\n",
      "1503/1503 [==============================] - 0s 186us/step - loss: 0.3668 - acc: 0.8436\n",
      "Epoch 22/40\n",
      "1503/1503 [==============================] - 0s 187us/step - loss: 0.3647 - acc: 0.8430\n",
      "Epoch 23/40\n",
      "1503/1503 [==============================] - 0s 187us/step - loss: 0.3674 - acc: 0.8403\n",
      "Epoch 24/40\n",
      "1503/1503 [==============================] - 0s 195us/step - loss: 0.3645 - acc: 0.8463\n",
      "Epoch 25/40\n",
      "1503/1503 [==============================] - 0s 191us/step - loss: 0.3641 - acc: 0.8430\n",
      "Epoch 26/40\n",
      "1503/1503 [==============================] - 0s 189us/step - loss: 0.3633 - acc: 0.8397\n",
      "Epoch 27/40\n",
      "1503/1503 [==============================] - 0s 185us/step - loss: 0.3647 - acc: 0.8443\n",
      "Epoch 28/40\n",
      "1503/1503 [==============================] - 0s 186us/step - loss: 0.3634 - acc: 0.8403\n",
      "Epoch 29/40\n",
      "1503/1503 [==============================] - 0s 188us/step - loss: 0.3613 - acc: 0.8417\n",
      "Epoch 30/40\n",
      "1503/1503 [==============================] - 0s 189us/step - loss: 0.3608 - acc: 0.8390\n",
      "Epoch 31/40\n",
      "1503/1503 [==============================] - 0s 187us/step - loss: 0.3612 - acc: 0.8357\n",
      "Epoch 32/40\n",
      "1503/1503 [==============================] - 0s 188us/step - loss: 0.3590 - acc: 0.8390\n",
      "Epoch 33/40\n",
      "1503/1503 [==============================] - 0s 194us/step - loss: 0.3586 - acc: 0.8403\n",
      "Epoch 34/40\n",
      "1503/1503 [==============================] - 0s 189us/step - loss: 0.3610 - acc: 0.8443\n",
      "Epoch 35/40\n",
      "1503/1503 [==============================] - 0s 188us/step - loss: 0.3570 - acc: 0.8403\n",
      "Epoch 36/40\n",
      "1503/1503 [==============================] - 0s 188us/step - loss: 0.3614 - acc: 0.8383\n",
      "Epoch 37/40\n",
      "1503/1503 [==============================] - 0s 195us/step - loss: 0.3598 - acc: 0.8417\n",
      "Epoch 38/40\n",
      "1503/1503 [==============================] - 0s 190us/step - loss: 0.3568 - acc: 0.8383\n",
      "Epoch 39/40\n",
      "1503/1503 [==============================] - 0s 191us/step - loss: 0.3609 - acc: 0.8423\n",
      "Epoch 40/40\n",
      "1503/1503 [==============================] - 0s 195us/step - loss: 0.3563 - acc: 0.8436\n"
     ]
    }
   ],
   "source": [
    "history = aspect_categories_model.fit(aspect_tokenized, aspect_dummy_category , epochs=40, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Aspect Category Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['FOOD#QUALITY']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ayush/anaconda2/envs/my_python_3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "new_review = \"This dessert is delicious!!!\"\n",
    "\n",
    "chunks = [(chunk.root.text) for chunk in spacy_parser(new_review).noun_chunks if chunk.root.pos_ == 'NOUN']\n",
    "new_review_aspect_terms = ' '.join(chunks)\n",
    "new_review_aspect_tokenized = tokenizer.texts_to_matrix([new_review_aspect_terms])\n",
    "\n",
    "new_review_category = label_encoder.inverse_transform(aspect_categories_model.predict_classes(new_review_aspect_tokenized))\n",
    "print(new_review_category)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the Sentiment Terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Aspect_Category</th>\n",
       "      <th>Specific_Target_Aspect_Term</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Specific_Target_Sentiment_Term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>AMBIENCE#GENERAL</td>\n",
       "      <td>seating</td>\n",
       "      <td>short and sweet â€“ seating is great:it's romant...</td>\n",
       "      <td>short sweet great be romantic cozy private</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>AMBIENCE#GENERAL</td>\n",
       "      <td>trattoria</td>\n",
       "      <td>This quaint and romantic trattoria is at the t...</td>\n",
       "      <td>quaint romantic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>positive</td>\n",
       "      <td>FOOD#QUALITY</td>\n",
       "      <td>food</td>\n",
       "      <td>The have over 100 different beers to offer thi...</td>\n",
       "      <td>different offer thi happy delicious recommend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>SERVICE#GENERAL</td>\n",
       "      <td>STAFF</td>\n",
       "      <td>THIS STAFF SHOULD BE FIRED.</td>\n",
       "      <td>should be</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>FOOD#STYLE_OPTIONS</td>\n",
       "      <td>menu</td>\n",
       "      <td>The menu looked great, and the waiter was very...</td>\n",
       "      <td>look great nice come average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>positive</td>\n",
       "      <td>FOOD#QUALITY</td>\n",
       "      <td>tuna</td>\n",
       "      <td>The tuna and wasabe potatoes are excellent.</td>\n",
       "      <td>excellent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>negative</td>\n",
       "      <td>SERVICE#GENERAL</td>\n",
       "      <td>staff</td>\n",
       "      <td>The whole set up is truly unprofessional and I...</td>\n",
       "      <td>unprofessional wish good current great</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>negative</td>\n",
       "      <td>SERVICE#GENERAL</td>\n",
       "      <td>service</td>\n",
       "      <td>sometimes i get bad food and bad service, some...</td>\n",
       "      <td>bad bad good good bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>positive</td>\n",
       "      <td>FOOD#STYLE_OPTIONS</td>\n",
       "      <td>BBQ ribs</td>\n",
       "      <td>This place has the best Chinese style BBQ ribs...</td>\n",
       "      <td>good chinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>positive</td>\n",
       "      <td>AMBIENCE#GENERAL</td>\n",
       "      <td>place</td>\n",
       "      <td>Great place to relax and enjoy your dinner</td>\n",
       "      <td>great relax enjoy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Polarity     Aspect_Category Specific_Target_Aspect_Term  \\\n",
       "0  positive    AMBIENCE#GENERAL                     seating   \n",
       "1  positive    AMBIENCE#GENERAL                   trattoria   \n",
       "2  positive        FOOD#QUALITY                        food   \n",
       "3  negative     SERVICE#GENERAL                       STAFF   \n",
       "4  positive  FOOD#STYLE_OPTIONS                        menu   \n",
       "5  positive        FOOD#QUALITY                        tuna   \n",
       "6  negative     SERVICE#GENERAL                       staff   \n",
       "7  negative     SERVICE#GENERAL                     service   \n",
       "8  positive  FOOD#STYLE_OPTIONS                    BBQ ribs   \n",
       "9  positive    AMBIENCE#GENERAL                       place   \n",
       "\n",
       "                                            Sentence  \\\n",
       "0  short and sweet â€“ seating is great:it's romant...   \n",
       "1  This quaint and romantic trattoria is at the t...   \n",
       "2  The have over 100 different beers to offer thi...   \n",
       "3                        THIS STAFF SHOULD BE FIRED.   \n",
       "4  The menu looked great, and the waiter was very...   \n",
       "5        The tuna and wasabe potatoes are excellent.   \n",
       "6  The whole set up is truly unprofessional and I...   \n",
       "7  sometimes i get bad food and bad service, some...   \n",
       "8  This place has the best Chinese style BBQ ribs...   \n",
       "9         Great place to relax and enjoy your dinner   \n",
       "\n",
       "                  Specific_Target_Sentiment_Term  \n",
       "0     short sweet great be romantic cozy private  \n",
       "1                                quaint romantic  \n",
       "2  different offer thi happy delicious recommend  \n",
       "3                                      should be  \n",
       "4                   look great nice come average  \n",
       "5                                      excellent  \n",
       "6         unprofessional wish good current great  \n",
       "7                          bad bad good good bad  \n",
       "8                                   good chinese  \n",
       "9                              great relax enjoy  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Specific_Target_Sentiment_Term = []\n",
    "for review in spacy_parser.pipe(train_df['Sentence']):\n",
    "        if review.is_parsed:\n",
    "            Specific_Target_Sentiment_Term.append(' '.join([token.lemma_ for token in review if (not token.is_stop and not token.is_punct and (token.pos_ == \"ADJ\" or token.pos_ == \"VERB\"))]))\n",
    "        else:\n",
    "            Specific_Target_Sentiment_Term.append('')  \n",
    "train_df['Specific_Target_Sentiment_Term'] = Specific_Target_Sentiment_Term\n",
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the Sentiment Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_model = Sequential()\n",
    "sentiment_model.add(Dense(512, input_shape=(vocab_size,), activation='relu'))\n",
    "sentiment_model.add(Dense(num_sentiments, activation='softmax'))\n",
    "sentiment_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_sentiment = pd.DataFrame(tokenizer.texts_to_matrix(train_df.Specific_Target_Sentiment_Term))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder_2 = LabelEncoder()\n",
    "sentiment_integer_category = label_encoder_2.fit_transform(train_df.Polarity)\n",
    "sentiment_dummy_category = to_categorical(sentiment_integer_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "1503/1503 [==============================] - 1s 333us/step - loss: 0.7986 - acc: 0.7019\n",
      "Epoch 2/40\n",
      "1503/1503 [==============================] - 0s 188us/step - loss: 0.5036 - acc: 0.7984\n",
      "Epoch 3/40\n",
      "1503/1503 [==============================] - 0s 189us/step - loss: 0.3912 - acc: 0.8530\n",
      "Epoch 4/40\n",
      "1503/1503 [==============================] - 0s 189us/step - loss: 0.3277 - acc: 0.8656\n",
      "Epoch 5/40\n",
      "1503/1503 [==============================] - 0s 187us/step - loss: 0.2928 - acc: 0.8749\n",
      "Epoch 6/40\n",
      "1503/1503 [==============================] - 0s 187us/step - loss: 0.2704 - acc: 0.8836\n",
      "Epoch 7/40\n",
      "1503/1503 [==============================] - 0s 188us/step - loss: 0.2480 - acc: 0.8922\n",
      "Epoch 8/40\n",
      "1503/1503 [==============================] - 0s 189us/step - loss: 0.2369 - acc: 0.8922\n",
      "Epoch 9/40\n",
      "1503/1503 [==============================] - 0s 195us/step - loss: 0.2256 - acc: 0.8982\n",
      "Epoch 10/40\n",
      "1503/1503 [==============================] - 0s 187us/step - loss: 0.2168 - acc: 0.8975\n",
      "Epoch 11/40\n",
      "1503/1503 [==============================] - 0s 191us/step - loss: 0.2152 - acc: 0.8942\n",
      "Epoch 12/40\n",
      "1503/1503 [==============================] - 0s 192us/step - loss: 0.2036 - acc: 0.9002\n",
      "Epoch 13/40\n",
      "1503/1503 [==============================] - 0s 190us/step - loss: 0.1956 - acc: 0.9009\n",
      "Epoch 14/40\n",
      "1503/1503 [==============================] - 0s 190us/step - loss: 0.1998 - acc: 0.8989\n",
      "Epoch 15/40\n",
      "1503/1503 [==============================] - 0s 191us/step - loss: 0.1924 - acc: 0.8989\n",
      "Epoch 16/40\n",
      "1503/1503 [==============================] - 0s 195us/step - loss: 0.1900 - acc: 0.8962\n",
      "Epoch 17/40\n",
      "1503/1503 [==============================] - 0s 192us/step - loss: 0.1891 - acc: 0.9035\n",
      "Epoch 18/40\n",
      "1503/1503 [==============================] - 0s 191us/step - loss: 0.1844 - acc: 0.9015\n",
      "Epoch 19/40\n",
      "1503/1503 [==============================] - 0s 189us/step - loss: 0.1801 - acc: 0.9029\n",
      "Epoch 20/40\n",
      "1503/1503 [==============================] - 0s 190us/step - loss: 0.1795 - acc: 0.9049\n",
      "Epoch 21/40\n",
      "1503/1503 [==============================] - 0s 188us/step - loss: 0.1791 - acc: 0.8989\n",
      "Epoch 22/40\n",
      "1503/1503 [==============================] - 0s 189us/step - loss: 0.1773 - acc: 0.9095\n",
      "Epoch 23/40\n",
      "1503/1503 [==============================] - 0s 193us/step - loss: 0.1731 - acc: 0.9069\n",
      "Epoch 24/40\n",
      "1503/1503 [==============================] - 0s 191us/step - loss: 0.1731 - acc: 0.9075\n",
      "Epoch 25/40\n",
      "1503/1503 [==============================] - 0s 190us/step - loss: 0.1709 - acc: 0.9075\n",
      "Epoch 26/40\n",
      "1503/1503 [==============================] - 0s 189us/step - loss: 0.1674 - acc: 0.9088\n",
      "Epoch 27/40\n",
      "1503/1503 [==============================] - 0s 194us/step - loss: 0.1663 - acc: 0.9088\n",
      "Epoch 28/40\n",
      "1503/1503 [==============================] - 0s 193us/step - loss: 0.1676 - acc: 0.9115\n",
      "Epoch 29/40\n",
      "1503/1503 [==============================] - 0s 191us/step - loss: 0.1666 - acc: 0.9088\n",
      "Epoch 30/40\n",
      "1503/1503 [==============================] - 0s 191us/step - loss: 0.1686 - acc: 0.9082\n",
      "Epoch 31/40\n",
      "1503/1503 [==============================] - 0s 190us/step - loss: 0.1640 - acc: 0.9122\n",
      "Epoch 32/40\n",
      "1503/1503 [==============================] - 0s 190us/step - loss: 0.1638 - acc: 0.9029\n",
      "Epoch 33/40\n",
      "1503/1503 [==============================] - 0s 188us/step - loss: 0.1654 - acc: 0.9115\n",
      "Epoch 34/40\n",
      "1503/1503 [==============================] - 0s 189us/step - loss: 0.1628 - acc: 0.9128\n",
      "Epoch 35/40\n",
      "1503/1503 [==============================] - 0s 190us/step - loss: 0.1620 - acc: 0.9082\n",
      "Epoch 36/40\n",
      "1503/1503 [==============================] - 0s 194us/step - loss: 0.1607 - acc: 0.9095\n",
      "Epoch 37/40\n",
      "1503/1503 [==============================] - 0s 193us/step - loss: 0.1591 - acc: 0.9055\n",
      "Epoch 38/40\n",
      "1503/1503 [==============================] - 0s 198us/step - loss: 0.1600 - acc: 0.9055\n",
      "Epoch 39/40\n",
      "1503/1503 [==============================] - 0s 188us/step - loss: 0.1605 - acc: 0.9122\n",
      "Epoch 40/40\n",
      "1503/1503 [==============================] - 0s 188us/step - loss: 0.1593 - acc: 0.9122\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff50c37b0f0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_model.fit(tokenized_sentiment, sentiment_dummy_category, epochs=40, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Sentiment Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['positive']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ayush/anaconda2/envs/my_python_3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "new_review = \"This italian place is nice and cosy\"\n",
    "\n",
    "chunks = [(chunk.root.text) for chunk in spacy_parser(new_review).noun_chunks if chunk.root.pos_ == 'NOUN']\n",
    "new_review_aspect_terms = ' '.join(chunks)\n",
    "new_review_aspect_tokenized = tokenizer.texts_to_matrix([new_review_aspect_terms])\n",
    "\n",
    "new_review_category = label_encoder_2.inverse_transform(sentiment_model.predict_classes(new_review_aspect_tokenized))\n",
    "print(new_review_category)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the Full Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 1 is expressing a  positive opinion about SERVICE#GENERAL\n",
      "Review 2 is expressing a  positive opinion about SERVICE#GENERAL\n",
      "Review 3 is expressing a  negative opinion about FOOD#QUALITY\n",
      "Review 4 is expressing a  positive opinion about FOOD#QUALITY\n",
      "Review 5 is expressing a  negative opinion about AMBIENCE#GENERAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ayush/anaconda2/envs/my_python_3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/ayush/anaconda2/envs/my_python_3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "test_reviews = [\n",
    "    \"Good, fast service.\",\n",
    "    \"The hostess was very pleasant.\",\n",
    "    \"The bread was stale, the salad was overpriced and empty.\",\n",
    "    \"The food we ordered was excellent, although I wouldn't say the margaritas were anything to write home about.\",\n",
    "    \"This place has totally weird decor, stairs going up with mirrored walls - I am surprised how no one yet broke their head or fall off the stairs\"\n",
    "]\n",
    "\n",
    "# Aspect preprocessing\n",
    "test_reviews = [review.lower() for review in test_reviews]\n",
    "test_aspect_terms = []\n",
    "for review in spacy_parser.pipe(test_reviews):\n",
    "    chunks = [(chunk.root.text) for chunk in review.noun_chunks if chunk.root.pos_ == 'NOUN']\n",
    "    test_aspect_terms.append(' '.join(chunks))\n",
    "test_aspect_terms = pd.DataFrame(tokenizer.texts_to_matrix(test_aspect_terms))\n",
    "                             \n",
    "# Sentiment preprocessing\n",
    "test_sentiment_terms = []\n",
    "for review in spacy_parser.pipe(test_reviews):\n",
    "        if review.is_parsed:\n",
    "            test_sentiment_terms.append(' '.join([token.lemma_ for token in review if (not token.is_stop and not token.is_punct and (token.pos_ == \"ADJ\" or token.pos_ == \"VERB\"))]))\n",
    "        else:\n",
    "            test_sentiment_terms.append('') \n",
    "test_sentiment_terms = pd.DataFrame(tokenizer.texts_to_matrix(test_sentiment_terms))\n",
    "\n",
    "# Models output\n",
    "test_aspect_categories = label_encoder.inverse_transform(aspect_categories_model.predict_classes(test_aspect_terms))\n",
    "test_sentiment = label_encoder_2.inverse_transform(sentiment_model.predict_classes(test_sentiment_terms))\n",
    "for i in range(5):\n",
    "    print(\"Review \" + str(i+1) + \" is expressing a  \" + test_sentiment[i] + \" opinion about \" + test_aspect_categories[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
